# AUTOGENERATED! DO NOT EDIT! File to edit: 00_datos.ipynb (unless otherwise specified).

__all__ = ['DATA_DIR_COVID', 'asegura_archivos_covid_disponibles', 'columnas_comunes', 'arregla_cvegeo', 'daterange',
           'cross_join', 'marco_municipal_2019', 'carga_datos_covid19_MX', 'procesa_fechas', 'actualizar_datos_salud',
           'agrupa_casos_municipios', 'agrupar_casos_municipios_por_fecha', 'calcular_acumulativa_casos',
           'calcular_ventana_casos', 'leer_variables_municipales', 'unir_casos_estadisticas_municipales',
           'tabla_covid_indicadores_municipales', 'serie_covid_indicadores_municipales', 'municipios_urbanos']

# Cell
import os
import glob
import itertools
from fastcore.test import *
from pathlib import Path

import numpy as np
import pandas as pd
import geopandas as gpd
from datetime import timedelta, date, datetime
import csv

import seaborn as sns
import requests

import logging

# Cell
DATA_DIR_COVID = 'datos/secretaria_salud/'


# Cell
def asegura_archivos_covid_disponibles(fechas):
    '''
    Esta función genera un error si no están disponibles todos los archivos de casos COVID-19 en México
    de las fechas especificadas. Los nombres de archivos siguen el patrón con el que los publica la Secretaría de Salud:
    {AÑO}{MES}{DIA}COVID19MEXICO.csv.zip, por ejemplo 200413COVID19MEXICO.csv.zip
    '''
    for fecha in fechas:
        fecha_str = fecha.strftime("%y%m%d")
        file = os.path.join(DATA_DIR_COVID, f'{fecha_str}COVID19MEXICO.csv.zip')
        assert os.path.exists(file), f'{fecha_str} no disponible'


# Cell

def columnas_comunes(df_1, df_2):
    '''
    Obtiene la lista de columnas con el mismo nombre entre dos DataFrame
    '''
    return list(set(df_1.columns).intersection(df_2.columns))

# Cell

def arregla_cvegeo(df, campo_cvegeo='cvegeo', extraer_ent=False):
    '''
    Revisa que los indetificadores de municipio (clave entidad + clave municipio) tengan 5 digitos, si un identificador
    tiene 4 le agrega un cero. Esta corrección asume que el problema surgió de leer los identificadores como enteros
    lo cual provoca que se descarten los ceros a la izquierda.
    '''
    df[campo_cvegeo] = df[campo_cvegeo].apply(lambda x: '0' + x if len(x) == 4 else x)

    if extraer_ent:
        df[f'ent_{campo_cvegeo}'] = df[campo_cvegeo].str[:2]
    return df

def daterange(start_date, end_date):
    for n in range(int((end_date - start_date).days)):
        yield start_date + timedelta(n)

def cross_join(left, right):
    return (left.assign(key=1).merge(right.assign(key=1), on='key').drop('key', 1))

def marco_municipal_2019():
    # cuenta número de casos por resultado
    marco_2019 = gpd.read_file('datos/municipios/marco_2019.json')
    marco_2019.rename(columns={'CVE_ENT': 'CLAVE_ENTIDAD_RES',
                               'municipio_cvegeo': 'CLAVE_MUNICIPIO_RES',
                               'municipio_nombre': 'MUNICIPIO_RES'}, inplace=True)
    marco_2019.MUNICIPIO_RES = marco_2019.MUNICIPIO_RES.str.upper()

    marco_2019.drop(columns=['CVE_MUN'], inplace=True)
    return marco_2019



# Cell

def carga_datos_covid19_MX(fecha='200601', resolver_claves='si_no_binarias'):
    """
        Lee en un DataFrame el CSV con el reporte de casos de la Secretaría de Salud de México publicado en una fecha dada. Esta función
        también lee el diccionario de datos que acompaña a estas publicaciones para preparar algunos campos, en particular permite la funcionalidad
        de generar columnas binarias para datos con valores 'SI', 'No'.

        **Nota**: En esta versión la ruta esta y nombre de los archivos es fija. Asumimos que existe un directorio 'datos/secretaria_salud/'
        donde se encuentran todos los archivos.

        **Nota 2**: El catálogo Resultado_LAB del formato de datos 07-10-2020 tiene el primer renglón vacío, y el catálogo CLASIFICACION
        final tiene los dos primeros renglones vacíos **hay que borrarlos en el archivo**

        periodo: 'dia', 'historico'. Trae los datos de la fecha indicada o trae
        la serie de conjuntos de datos hasta la fecha indicada (por implementar).

        resolver_claves: 'sustitucion', 'agregar', 'si_no_binarias', 'solo_localidades'. Resuelve los valores del conjunto de datos usando el
        diccionario de datos y los catálogos. 'sustitucion' remplaza los valores en las columnas, 'agregar'
        crea nuevas columnas. 'si_no_binarias' cambia valores SI, NO, No Aplica, SE IGNORA, NO ESPECIFICADO por 1, 0, 0, 0, 0 respectivamente.

    """
    nuevo_formato=False
    fecha_carga = pd.to_datetime(fecha, yearfirst=True)

    if fecha_carga < pd.to_datetime('20-10-07', yearfirst=True):
        fecha_formato = '0412'
    elif ((fecha_carga >= pd.to_datetime('20-10-07', yearfirst=True))
          & (fecha_carga < pd.to_datetime('20-11-28', yearfirst=True))):
        fecha_formato = '071020'
        nuevo_formato = True
    else:
        fecha_formato = '201128'
        nuevo_formato = True


    catalogos=f'Catalogos_{fecha_formato}.xlsx'
    descriptores=f'Descriptores_{fecha_formato}.xlsx'

    diccionarios_path = Path('datos/secretaria_salud/diccionario_datos_covid19')
    catalogos = diccionarios_path/catalogos
    data_file = os.path.join(DATA_DIR_COVID, f'{fecha}COVID19MEXICO.csv.zip')
    df = pd.read_csv(data_file, dtype=object, encoding='latin-1')

    # Hay un error y el campo OTRA_COMP es OTRAS_COMP según los descriptores
    df.rename(columns={'OTRA_COM': 'OTRAS_COM'}, inplace=True)

    # Asignar clave única a municipios
    df['MUNICIPIO_RES'] = df['ENTIDAD_RES'] + df['MUNICIPIO_RES']
    df['CLAVE_MUNICIPIO_RES'] = df['MUNICIPIO_RES']

    # Leer catalogos
    nombres_catalogos = ['Catálogo de ENTIDADES',
                         'Catálogo MUNICIPIOS',
                         'Catálogo RESULTADO',
                         'Catálogo SI_NO',
                         'Catálogo TIPO_PACIENTE']

    if nuevo_formato:
        nombres_catalogos.append('Catálogo CLASIFICACION_FINAL')
        nombres_catalogos[2] = 'Catálogo RESULTADO_LAB'

    dict_catalogos = pd.read_excel(catalogos,
                              nombres_catalogos,
                              dtype=str,
                              engine='openpyxl')

    entidades = dict_catalogos[nombres_catalogos[0]]
    municipios = dict_catalogos[nombres_catalogos[1]]
    tipo_resultado = dict_catalogos[nombres_catalogos[2]]
    cat_si_no = dict_catalogos[nombres_catalogos[3]]
    cat_tipo_pac = dict_catalogos[nombres_catalogos[4]]

    if nuevo_formato:
        clasificacion_final = dict_catalogos[nombres_catalogos[5]]


    # Resolver códigos de entidad federal
    cols_entidad = ['ENTIDAD_RES', 'ENTIDAD_UM', 'ENTIDAD_NAC']
    df['CLAVE_ENTIDAD_RES'] = df['ENTIDAD_RES']
    df[cols_entidad] = df[cols_entidad].replace(to_replace=entidades['CLAVE_ENTIDAD'].values,
                                               value=entidades['ENTIDAD_FEDERATIVA'].values)

    # Contruye clave unica de municipios de catálogo para resolver nombres de municipio
    municipios['CLAVE_MUNICIPIO'] = municipios['CLAVE_ENTIDAD'] + municipios['CLAVE_MUNICIPIO']

    # Resolver códigos de municipio
    municipios_dict = dict(zip(municipios['CLAVE_MUNICIPIO'], municipios['MUNICIPIO']))
    df['MUNICIPIO_RES'] = df['MUNICIPIO_RES'].map(municipios_dict.get)

    # Resolver resultados
    if nuevo_formato:
        df.rename(columns={'RESULTADO_LAB': 'RESULTADO'}, inplace=True)
        tipo_resultado['DESCRIPCIÓN'].replace({'POSITIVO A SARS-COV-2': 'Positivo SARS-CoV-2'}, inplace=True)

    tipo_resultado = dict(zip(tipo_resultado['CLAVE'], tipo_resultado['DESCRIPCIÓN']))
    df['RESULTADO'] = df['RESULTADO'].map(tipo_resultado.get)

    # Resolver datos SI - NO

    # Necesitamos encontrar todos los campos que tienen este tipo de dato y eso
    # viene en los descriptores, en el campo FORMATO_O_FUENTE
    descriptores = pd.read_excel(diccionarios_path/descriptores,
                                 index_col='Nº',
                                 engine='openpyxl')
    descriptores.columns = list(map(lambda col: col.replace(' ', '_'), descriptores.columns))
    descriptores['FORMATO_O_FUENTE'] = descriptores.FORMATO_O_FUENTE.str.strip()

    datos_si_no = descriptores.query('FORMATO_O_FUENTE == "CATÁLOGO: SI_ NO"')
    cat_si_no['DESCRIPCIÓN'] = cat_si_no['DESCRIPCIÓN'].str.strip()

    campos_si_no = datos_si_no.NOMBRE_DE_VARIABLE
    nuevos_campos_si_no = campos_si_no

    if resolver_claves == 'agregar':
        nuevos_campos_si_no = [nombre_var + '_NOM' for nombre_var in campos_si_no]
    elif resolver_claves == 'si_no_binarias':
        nuevos_campos_si_no = [nombre_var + '_BIN' for nombre_var in campos_si_no]
        cat_si_no['DESCRIPCIÓN'] = list(map(lambda val: 1 if val == 'SI' else 0, cat_si_no['DESCRIPCIÓN']))

    df[nuevos_campos_si_no] = df[datos_si_no.NOMBRE_DE_VARIABLE].replace(
                                                to_replace=cat_si_no['CLAVE'].values,
                                                value=cat_si_no['DESCRIPCIÓN'].values)

    # Resolver tipos de paciente
    cat_tipo_pac = dict(zip(cat_tipo_pac['CLAVE'], cat_tipo_pac['DESCRIPCIÓN']))
    df['TIPO_PACIENTE'] = df['TIPO_PACIENTE'].map(cat_tipo_pac.get)

    df = procesa_fechas(df)

    return df

# Cell

def procesa_fechas(covid_df):
    df = covid_df.copy()

    df['FECHA_INGRESO'] = pd.to_datetime(df['FECHA_INGRESO'])
    df['FECHA_SINTOMAS'] = pd.to_datetime(df['FECHA_SINTOMAS'])
    df['FECHA_DEF'] = pd.to_datetime(df['FECHA_DEF'], 'coerce')
    df['DEFUNCION'] = (df['FECHA_DEF'].notna()).astype(int)
    df['EDAD'] = df['EDAD'].astype(int)

    df.set_index('FECHA_INGRESO', drop=False, inplace=True)
    df['AÑO_INGRESO'] = df.index.year
    df['MES_INGRESO'] = df.index.month
    df['DIA_SEMANA_INGRESO'] = df.index.weekday
    df['SEMANA_AÑO_INGRESO'] = df.index.isocalendar().week
    df['DIA_MES_INGRESO'] = df.index.day
    df['DIA_AÑO_INGRESO'] = df.index.dayofyear

    return df

# Cell

def actualizar_datos_salud(directorio_datos='./datos/secretaria_salud/', fecha_inicio='12-04-2020'):
    '''
        Descarga todos los archivos de datos hasta el día anterior a la fecha actual. Si los archivos
        ya existen en el directorio entonces no los descarga.
    '''
    url_salud_historicos = 'http://datosabiertos.salud.gob.mx/gobmx/salud/datos_abiertos/historicos/'    
    ayer = date.today() - timedelta(days=1)
    fecha_inicio = datetime.strptime(fecha_inicio, "%d-%m-%Y")
    for fecha in daterange(fecha_inicio.date(), ayer):
        archivo_nombre = f'{fecha.strftime("%y%m%d")}COVID19MEXICO.csv.zip'
        archivo_ruta = os.path.join(directorio_datos, archivo_nombre)
        if os.path.exists(archivo_ruta):
            logging.debug(f'Ya existe {archivo_nombre}')
        else:
            print(f'Bajando datos {fecha.strftime("%d.%m.%Y")}')
            url_dia = "{}/{}/datos_abiertos_covid19_{}.zip".format(fecha.strftime('%Y'),
                                                                   fecha.strftime('%m'),
                                                                   fecha.strftime('%d.%m.%Y'))
            url = url_salud_historicos + url_dia
            r = requests.get(url, allow_redirects=True)
            open(archivo_ruta, 'wb').write(r.content)


# Cell

def agrupa_casos_municipios(casos_df):
    '''
        Este método crea una tabla con todos los municipios y el número de casos registrados
            para cada tipo de paciente y para cada resultado.
    '''
    casos_df = casos_df.copy()

    # cuenta número de casos por resultado
    marco_2019 = gpd.read_file('datos/municipios/marco_2019.json')
    marco_2019.rename(columns={'CVE_ENT': 'CLAVE_ENTIDAD_RES',
                               'municipio_cvegeo': 'CLAVE_MUNICIPIO_RES',
                               'municipio_nombre': 'MUNICIPIO_RES'}, inplace=True)
    marco_2019.MUNICIPIO_RES = marco_2019.MUNICIPIO_RES.str.upper()

    # poblacion_2020 = pd.read_csv('datos/municipios/proyeccion_poblacion_2020.csv',
    #                         dtype={'cve_ent': object, 'cve_mun': object, 'pob2020': int})

    if 'geometry' in casos_df.columns:
        casos_df.drop(columns='geometry', inplace=True)

    claves_municipio = marco_2019.CLAVE_MUNICIPIO_RES.unique()
    tipos_resultado = casos_df.RESULTADO.unique()

    # claves_entidades = casos_df[['CLAVE_ENTIDAD_RES', 'ENTIDAD_RES']].drop_duplicates()

    # primero armamos la tabla de municipios y todos los tipos de casos, para luego llenar los conteos de cada tipo
    # para cada municipio
    tipos_caso_municipio = set(itertools.product(claves_municipio, tipos_resultado))
    tipos_caso_municipio = pd.DataFrame(tipos_caso_municipio, columns={'CLAVE_MUNICIPIO_RES': str, 'RESULTADO': str})

    # agregamos nombres y claves de entidad
    # poblacion_2020.rename(columns={'cve_ent': 'CLAVE_ENTIDAD_RES', 'cve_mun': 'CLAVE_MUNICIPIO_RES'}, inplace=True)
    tipos_caso_municipio = marco_2019.merge(tipos_caso_municipio, on=['CLAVE_MUNICIPIO_RES'], how='left')
    tipos_caso_municipio = tipos_caso_municipio.merge(casos_df[['CLAVE_ENTIDAD_RES', 'ENTIDAD_RES']].drop_duplicates(),
                                                      on=['CLAVE_ENTIDAD_RES'], how='left')

    # ahora contamos que ha pasado en cada municipio
    cols_localidad = ['ENTIDAD_RES', 'MUNICIPIO_RES', 'CLAVE_MUNICIPIO_RES']
    covid_municipal = casos_df[cols_localidad + ['RESULTADO', 'DEFUNCION']].groupby(cols_localidad + ['RESULTADO'])

    # claves_entidades = casos_df[['CLAVE_ENTIDAD_RES', 'ENTIDAD_RES']].drop_duplicates()

    covid_municipal = covid_municipal.agg({'RESULTADO':'count', 'DEFUNCION':sum})
    covid_municipal.rename(columns={'RESULTADO': 'conteo', 'DEFUNCION': 'defunciones'}, level=0, inplace=True)
    covid_municipal.reset_index(inplace=True)

    covid_municipal = covid_municipal.merge(marco_2019, on=['CLAVE_MUNICIPIO_RES', 'MUNICIPIO_RES'])

    covid_municipal = tipos_caso_municipio.merge(covid_municipal, on=list(tipos_caso_municipio.columns), how='left')
    covid_municipal[['conteo', 'defunciones']] = covid_municipal[['conteo', 'defunciones']].fillna(0)
    covid_municipal.drop(columns=['CVE_MUN'], inplace=True)
    return covid_municipal


# Cell

def agrupar_casos_municipios_por_fecha(casos_df, por_fecha='ingreso', operacion='acumlativa'):
    '''
        Este método crea una tabla con todos los municipios y el número de casos registrados
            para cada tipo de paciente,  para cada resultado agrupados por el tipo de fecha especificado.

        Estatus: calcular las sumas de casos acumulada por fecha
    '''
    casos_df = casos_df.copy()
    cols_localidad = ['ENTIDAD_RES', 'CLAVE_ENTIDAD_RES', 'MUNICIPIO_RES', 'CLAVE_MUNICIPIO_RES']
    cols_interes = cols_localidad + ['RESULTADO', 'FECHA_INGRESO']
    casos_df.reset_index(drop=True, inplace=True)

    covid_municipal = casos_df[cols_interes + ['DEFUNCION']].groupby(cols_interes)
    covid_municipal = covid_municipal.agg({'RESULTADO':'count', 'DEFUNCION':sum})
    covid_municipal.rename(columns={'RESULTADO': 'conteo', 'DEFUNCION': 'defunciones'}, level=0, inplace=True)
    covid_municipal.reset_index(inplace=True)

    # cuenta casos y suma defunciones


    claves_municipio = covid_municipal.CLAVE_MUNICIPIO_RES.unique()
    tipos_resultado = covid_municipal.RESULTADO.unique()

    if por_fecha == 'ingreso':
        fechas = covid_municipal[covid_municipal.RESULTADO == 'Positivo SARS-CoV-2'].FECHA_INGRESO
        inicio = fechas.min()
        fin = fechas.max()

        fechas = list(daterange(inicio.date(), fin.date()))
    else:
        raise NotImplementedError

    # primero armamos la tabla de municipios y todos los tipos de casos, para luego llenar los conteos de cada tipo
    # para cada municipio

    tipos_caso_municipio = set(itertools.product(tipos_resultado, fechas))
    tipos_caso_municipio = pd.DataFrame(tipos_caso_municipio, columns={'RESULTADO': str,
                                                                       'FECHA_INGRESO': np.datetime64})

    tipos_caso_municipio = cross_join(covid_municipal[cols_localidad].drop_duplicates(), tipos_caso_municipio)
    tipos_caso_municipio.FECHA_INGRESO = pd.to_datetime(tipos_caso_municipio.FECHA_INGRESO)

    # ahora contamos que ha pasado en cada municipio por fechas
    covid_municipal = tipos_caso_municipio.merge(covid_municipal, how='left', on=cols_localidad + ['RESULTADO',
                                                                    'FECHA_INGRESO'])
    covid_municipal.fillna(0, inplace=True)
    covid_municipal = covid_municipal.merge(marco_municipal_2019(),
                                            on=['CLAVE_ENTIDAD_RES', 'CLAVE_MUNICIPIO_RES', 'MUNICIPIO_RES'])
    return covid_municipal


# Cell
def calcular_acumulativa_casos(casos_municipios_diarios, agregar_cols=False):
    df = casos_municipios_diarios.sort_values(by='FECHA_INGRESO').copy()

    df = df.groupby(['ENTIDAD_RES', 'CLAVE_ENTIDAD_RES',
                   'MUNICIPIO_RES', 'CLAVE_MUNICIPIO_RES',
                   'RESULTADO', 'FECHA_INGRESO']).sum()

    if agregar_cols:
        df[['acum_cont', 'acum_def']] = df.groupby(level=[0, 1, 2, 3, 4])[['conteo', 'defunciones']].transform('cumsum')
    else:
        df = df.groupby(level=[0, 1, 2, 3, 4]).cumsum()

    mun_geoms = casos_municipios_diarios[~casos_municipios_diarios.CLAVE_MUNICIPIO_RES.duplicated()][['CLAVE_MUNICIPIO_RES', 'geometry']]
    df = df.reset_index()

    df = df.merge(mun_geoms, on=['CLAVE_MUNICIPIO_RES'], how='left')
    df = gpd.GeoDataFrame(df, geometry='geometry')

    return df



# Cell
def calcular_ventana_casos(casos_municipios_diarios, dias_ventana=30):
    '''
    Agrega dos columnas: una con los casos acumulados en la ventana de tiempo especificada para la fecha respectiva,
    y la otra con las defuncionas acumuladas en la misma ventana de tiempo.
    '''
    df = casos_municipios_diarios.copy()

    df = df.set_index('FECHA_INGRESO')
    df.sort_index(inplace=True)

    rolling_grouping = df.groupby(['CLAVE_MUNICIPIO_RES',
                       'RESULTADO']).rolling(f'{dias_ventana}D')

    ventana_df = rolling_grouping[['conteo', 'defunciones']].sum()

    ventana_df.rename(columns={'conteo': f'conteo_{dias_ventana}dias',
                       'defunciones': f'defunciones_{dias_ventana}dias'},
            inplace=True)

    df = df.merge(ventana_df, on=['CLAVE_MUNICIPIO_RES', 'FECHA_INGRESO', 'RESULTADO'], how='left').reset_index()
    df = gpd.GeoDataFrame(df, geometry='geometry')

    return df


# Cell

def leer_variables_municipales():
    variables_municipales = pd.read_csv('datos/municipios/indicadores.csv', index_col=False,
                                        dtype={'cvegeo': str, 'entidad_cv': str,
                                              'municipio_cvegeo': str, 'entidad_cvegeo': str},
                                        encoding='iso8859_2')
    arregla_cvegeo(variables_municipales, 'municipio_cvegeo')
    arregla_cvegeo(variables_municipales, extraer_ent=True)

    variables_municipales.drop(columns=['municipio_cvegeo', 'entidad_cv'], inplace=True)
    marco_2019 = gpd.read_file('datos/municipios/marco_2019.json')
    marco_2019.rename(columns={'municipio_cvegeo': 'cvegeo'}, inplace=True)
    # marco_2019 = marco_2019[['municipio_cvegeo', 'geometry', 'municipio_nombre']]
    variables_municipales = variables_municipales.merge(marco_2019, on='cvegeo')

    # variables_municipales.drop(columns='nom_mun', inplace=True)
    # variables_municipales.rename(columns={'municipio_nombre': 'nom_mun'}, inplace=True)
    return variables_municipales

# Cell
def unir_casos_estadisticas_municipales(casos_municipios_df, estats_municipios):
    cols_com = columnas_comunes(casos_municipios_df, estats_municipios)
    casos_municipios_df = casos_municipios_df.merge(estats_municipios,
                                      left_on=['CLAVE_MUNICIPIO_RES'] + cols_com,
                                      right_on=['cvegeo'] + cols_com, how='right')

    casos_municipios_df.drop(columns=['CVE_ENT', 'entidad_cvegeo', 'nom_mun', 'cvegeo',
                                      'nom_ent', 'municipio_nombre', 'id', 'ent_cvegeo', 'pob01'], inplace=True)

    return casos_municipios_df

# Cell

def tabla_covid_indicadores_municipales(fecha, solo_positivos=True):
    covid_df = carga_datos_covid19_MX(fecha)
    covid_mun_df = agrupa_casos_municipios(covid_df)
    mun_df = leer_variables_municipales()
    mun_df.drop(columns=['geometry'])
    covid_mun_df = unir_casos_estadisticas_municipales(covid_mun_df, mun_df)

    if solo_positivos:
        covid_mun_df = covid_mun_df[covid_mun_df.RESULTADO == 'Positivo SARS-CoV-2']
    return covid_mun_df

# Cell
def serie_covid_indicadores_municipales(fecha=None,
                                        covid_df=None,
                                        solo_positivos=True,
                                        acumulativa=True,
                                        dias=30):

    if fecha:
        try:
            covid_df = carga_datos_covid19_MX(fecha)
        except KeyError as e:
            print(f'Error con fecha {fecha}')
            print(e)

    covid_mun_df = agrupar_casos_municipios_por_fecha(covid_df)

    if acumulativa:
        covid_mun_df = calcular_acumulativa_casos(covid_mun_df).reset_index(drop=True)
    else:
        covid_mun_df = calcular_ventana_casos(covid_mun_df, dias)

    mun_df = leer_variables_municipales()
    mun_df.drop(columns=['geometry'])
    covid_mun_df = unir_casos_estadisticas_municipales(covid_mun_df, mun_df)
    covid_mun_df.drop(columns='CVE_MUN', inplace=True)
    if solo_positivos:
        covid_mun_df = covid_mun_df[covid_mun_df.RESULTADO == 'Positivo SARS-CoV-2']

    covid_mun_df = gpd.GeoDataFrame(covid_mun_df, geometry='geometry')
    return covid_mun_df



# Cell

def municipios_urbanos():
    archivo = 'datos/municipios/municipios_ciudades.csv'

    df = pd.read_csv(archivo, dtype=str)
    df.dropna(inplace=True)
    df.rename(columns={'municipio_cvegeo': "CLAVE_MUNICIPIO"}, inplace=True)
    return df
